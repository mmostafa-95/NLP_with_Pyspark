{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c9da32d6",
      "metadata": {
        "id": "c9da32d6"
      },
      "source": [
        "# NLP Using PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8326ba88",
      "metadata": {
        "id": "8326ba88"
      },
      "source": [
        "## Objective:\n",
        "- The objective from this project is to create a <b>Spam filter using NaiveBayes classifier</b>.\n",
        "- It is required to obtain <b>f1_scored > 0.9</b>.\n",
        "- We'll use a dataset from UCI Repository. SMS Spam Detection: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e31bc851",
      "metadata": {
        "id": "e31bc851"
      },
      "source": [
        "### Creating a spark session and importing the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dcf86e46",
      "metadata": {
        "id": "dcf86e46"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as pyf\n",
        "from pyspark.ml.feature import Tokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "s_Bh15-gZhFd",
      "metadata": {
        "id": "s_Bh15-gZhFd"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d00718f",
      "metadata": {
        "id": "2d00718f"
      },
      "source": [
        "### Reading the data into a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "29914cf1",
      "metadata": {
        "id": "29914cf1"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv('SMSSpamCollection', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b52706b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b52706b9",
        "outputId": "5b2b9440-767d-4f28-ca47-727ba587b80e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- _c1: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f1a88df6",
      "metadata": {
        "id": "f1a88df6",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "new_df = df.withColumnRenamed('_c0', 'class').withColumnRenamed('_c1', 'text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "362dcb99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "362dcb99",
        "outputId": "6fa20dae-4c46-465f-daea-aed977857d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|class|                text|\n",
            "+-----+--------------------+\n",
            "|  ham|Go until jurong p...|\n",
            "|  ham|Ok lar... Joking ...|\n",
            "| spam|Free entry in 2 a...|\n",
            "|  ham|U dun say so earl...|\n",
            "|  ham|Nah I don't think...|\n",
            "| spam|FreeMsg Hey there...|\n",
            "|  ham|Even my brother i...|\n",
            "|  ham|As per your reque...|\n",
            "| spam|WINNER!! As a val...|\n",
            "| spam|Had your mobile 1...|\n",
            "+-----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "new_df.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fe744a9",
      "metadata": {
        "id": "2fe744a9"
      },
      "source": [
        "## Clean and Prepare the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d693167",
      "metadata": {
        "id": "4d693167"
      },
      "source": [
        "### Creating a new feature column contains the length of the text column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5424a0cb",
      "metadata": {
        "id": "5424a0cb"
      },
      "outputs": [],
      "source": [
        "df_len = new_df.withColumn('length', pyf.length(pyf.col('text')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "Wlj07LL-fa5d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlj07LL-fa5d",
        "outputId": "f38abe48-a1a4-4686-fd4f-b6c78c04549e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+------+\n",
            "|class|                text|length|\n",
            "+-----+--------------------+------+\n",
            "|  ham|Go until jurong p...|   111|\n",
            "|  ham|Ok lar... Joking ...|    29|\n",
            "| spam|Free entry in 2 a...|   155|\n",
            "|  ham|U dun say so earl...|    49|\n",
            "|  ham|Nah I don't think...|    61|\n",
            "| spam|FreeMsg Hey there...|   147|\n",
            "|  ham|Even my brother i...|    77|\n",
            "|  ham|As per your reque...|   160|\n",
            "| spam|WINNER!! As a val...|   157|\n",
            "| spam|Had your mobile 1...|   154|\n",
            "|  ham|I'm gonna be home...|   109|\n",
            "| spam|SIX chances to wi...|   136|\n",
            "| spam|URGENT! You have ...|   155|\n",
            "|  ham|I've been searchi...|   196|\n",
            "|  ham|I HAVE A DATE ON ...|    35|\n",
            "| spam|XXXMobileMovieClu...|   149|\n",
            "|  ham|Oh k...i'm watchi...|    26|\n",
            "|  ham|Eh u remember how...|    81|\n",
            "|  ham|Fine if thatÂ’s th...|    56|\n",
            "| spam|England v Macedon...|   155|\n",
            "+-----+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_len.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "692e37a6",
      "metadata": {
        "id": "692e37a6"
      },
      "source": [
        "### Geting the average text length for each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "I_W1RO-Ffo7k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_W1RO-Ffo7k",
        "outputId": "134b18b9-b46d-47a6-bd3d-a32bf3383930"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----------------+\n",
            "|class|      Avg. Length|\n",
            "+-----+-----------------+\n",
            "|  ham|71.45431945307645|\n",
            "| spam|138.6706827309237|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_len.groupBy('class').agg(pyf.avg('length').alias('Avg. Length')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5e101af",
      "metadata": {
        "id": "d5e101af"
      },
      "source": [
        "## Feature Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "838ad9dd",
      "metadata": {
        "id": "838ad9dd"
      },
      "source": [
        "### In this part I transform the raw text in to tf_idf model :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "225067d5",
      "metadata": {
        "id": "225067d5"
      },
      "source": [
        "### Performing the following steps to obtain TF-IDF:\n",
        "1. Creating a <b>Tokenizer</b> from the text column.\n",
        "2. Creating a <b>StopWordsRemover</b> to remove the <b>stop words</b> from the column obtained from the <b>Tokenizer</b>.\n",
        "3. Creating a <b>CountVectorizer</b> after removing the <b>stop words</b>.\n",
        "4. Creating the <b>TF-IDF</b> from the <b>CountVectorizer</b>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6a4eebf8",
      "metadata": {
        "id": "6a4eebf8"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "count_vec = CountVectorizer(inputCol='stop_tokens',outputCol='c_vec')\n",
        "idf = IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1527ad65",
      "metadata": {
        "id": "1527ad65"
      },
      "source": [
        "- Converting the <b>class column</b> to index using <b>StringIndexer</b>\n",
        "- Creating feature column from the <b>TF-IDF</b> and <b>length</b> columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "aaf46159",
      "metadata": {
        "id": "aaf46159"
      },
      "outputs": [],
      "source": [
        "hamSpamNum = StringIndexer(inputCol='class',outputCol='label')\n",
        "vecAssembler = VectorAssembler(inputCols=['tf_idf','length'],outputCol='features')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9775d494",
      "metadata": {
        "id": "9775d494"
      },
      "source": [
        "## The Model\n",
        "- Creating a <b>NaiveBayes</b> classifier with the default parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "57af0d5d",
      "metadata": {
        "id": "57af0d5d"
      },
      "outputs": [],
      "source": [
        "nbModel = NaiveBayes(featuresCol='features', labelCol='label')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc14de63",
      "metadata": {
        "id": "dc14de63"
      },
      "source": [
        "## Pipeline\n",
        "### Creating a pipeline model contains all the steps starting from the Tokenizer to the NaiveBays classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8ee0d1ca",
      "metadata": {
        "id": "8ee0d1ca"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(stages=[tokenizer,stopremove, count_vec, idf, hamSpamNum, vecAssembler, nbModel])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5d7efbe",
      "metadata": {
        "id": "f5d7efbe"
      },
      "source": [
        "### Spliting the data to trian and test data with ratios 0.7 and 0.3 respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2843d997",
      "metadata": {
        "id": "2843d997"
      },
      "outputs": [],
      "source": [
        "trainDF, testDF = df_len.randomSplit([.7,.3],seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bcea576",
      "metadata": {
        "id": "8bcea576"
      },
      "source": [
        "### Fitting your Pipeline model to the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3c5d4681",
      "metadata": {
        "id": "3c5d4681"
      },
      "outputs": [],
      "source": [
        "pipelineModel = pipeline.fit(trainDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228a3eb1",
      "metadata": {
        "id": "228a3eb1"
      },
      "source": [
        "### Performing predictions on tests dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "14f4aab5",
      "metadata": {
        "id": "14f4aab5"
      },
      "outputs": [],
      "source": [
        "predDF = pipelineModel.transform(testDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bce2885f",
      "metadata": {
        "id": "bce2885f"
      },
      "source": [
        "### Printing the schema of the prediction dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "25ByeIapomxX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25ByeIapomxX",
        "outputId": "d52c29a4-d8ca-43f3-861a-f046c449521c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- class: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- length: integer (nullable = true)\n",
            " |-- token_text: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- stop_tokens: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- c_vec: vector (nullable = true)\n",
            " |-- tf_idf: vector (nullable = true)\n",
            " |-- label: double (nullable = false)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- rawPrediction: vector (nullable = true)\n",
            " |-- probability: vector (nullable = true)\n",
            " |-- prediction: double (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predDF.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f27055",
      "metadata": {
        "id": "57f27055"
      },
      "source": [
        "## Model Evaluation\n",
        "- Using <b>MulticlassClassificationEvaluator</b> to calculate the <b>f1_score</b>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "61911086",
      "metadata": {
        "id": "61911086"
      },
      "outputs": [],
      "source": [
        "classificationEvaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='f1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "be706565",
      "metadata": {
        "id": "be706565"
      },
      "outputs": [],
      "source": [
        "f1 = classificationEvaluator.evaluate(predDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "GUHhZmT1qbh-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUHhZmT1qbh-",
        "outputId": "608ff5dc-8f38-4bfb-97fc-696317bfe9c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score is 0.9727502290227267\n"
          ]
        }
      ],
      "source": [
        "print(f\"f1_score is {f1}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Mohamed_Mostafa_Serry_MansG1_ Spark and Python for Big Data Final Exam-Branches.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
